import torch
import numpy as np
from typing import List
import torch.nn as nn
import sys
import argparse
import os
import time

sys.path.append('../')
import quantization as q
from fracbnn_cifar10 import resnet20


class ConvParam:
    def __init__(self):
        pass


def convert_to_binary(values):
    bin_str = ''.join(['1' if x > 0 else '0' for x in values])
    bin_str = bin_str.ljust(64, '0')
    return int(bin_str, 2)


def extract_all_conv_layers(model):
    conv_layers = []

    for sub_module in model.modules():
        if isinstance(sub_module, (q.BinaryConv2d, q.PGBinaryConv2d, nn.Conv2d)):
            conv_layers.append(sub_module)

    return conv_layers

def process_weights(layers):
    processed_weights = np.zeros((45, 16, 3, 3), dtype=np.uint64)
    weight_index = 0

    for idx, layer in enumerate(layers):
        weights = layer.weight.detach().numpy()
        print(f'Processing layer {idx}, weight shape: {weights.shape}')

        if idx == 0:
            for c in range(3):
                for och in range(16):
                    for h in range(3):
                        for w in range(3):
                            start_index = c * 32
                            end_index = (c + 1) * 32
                            binary_chunk = weights[och, start_index:end_index, h, w]
                            processed_weights[weight_index, och, h, w] = convert_to_binary(binary_chunk)
                weight_index += 1
        else:
            och, ich, kh, kw = weights.shape
            packs = och // 16
            bit_width = 64 if ich >= 64 else (32 if ich >= 32 else 16)

            for pack in range(packs):
                for och_idx in range(16):
                    for h in range(3):
                        for w in range(3):
                            if bit_width == 16:
                                binary_chunk = weights[pack * 16 + och_idx, :16, h, w]
                            elif bit_width == 32:
                                binary_chunk = weights[pack * 16 + och_idx, :32, h, w]
                            else:
                                binary_chunk = weights[pack * 16 + och_idx, :64, h, w]
                            processed_weights[weight_index, och_idx, h, w] = convert_to_binary(binary_chunk)
                weight_index += 1

    return processed_weights


def write_hls_weights(weights, output_path):
    if not os.path.exists(output_path):
        os.makedirs(output_path)

    with open(os.path.join(output_path, 'conv_weights.h'), 'w') as f:
        f.write(f'''/********************************************************************************
* Filename: weights.h
* Date: {time.ctime()}
* Description: This file is generated by the script.
********************************************************************************/

#include "typedefs.h"

''')

        f.write(f"const uint64 conv_weight_all[45][16][3][3] = ")
        print_ndarray_recursion(weights, lambda x: f"0x{x:016x}", f)
        f.write(';\n')



def print_ndarray_recursion(arr, str_func=str, file=sys.stdout, stop=0):
    if not hasattr(arr, '__iter__') or len(arr.shape) == stop:
        print(str_func(arr), file=file, end='')
        return
    ends = '' if (len(arr.shape) == stop + 1) else '\n'
    print('{', file=file, end='')
    for i, item in enumerate(arr):
        print_ndarray_recursion(item, str_func, file, stop)
        if i != len(arr) - 1: print(',', file=file, end=ends)
    print(ends + '}', file=file, end='')


if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('-w', '--weight', required=True, help='.pt file name to load weights from')
    parser.add_argument('-o', '--output', default='output', help='Directory to save extracted weights')
    args = parser.parse_args()

    # Load the model and the state dict
    ptfile = torch.load(args.weight, map_location='cpu')

    print("Keys in the .pt file:", ptfile.keys())

    model = resnet20()
    state_dict = model.state_dict()

    for key in state_dict.keys():
        if key in ptfile:
            state_dict[key] = ptfile[key]
        else:
            print(f"Key {key} not found in the .pt file")

    model.load_state_dict(state_dict, strict=False)
    model.eval()

    layers = extract_all_conv_layers(model)
    processed_weights = process_weights(layers)

    write_hls_weights(processed_weights, args.output)
